{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4216a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.dit import DiT\n",
    "from models import *\n",
    "from ddad_utils.dataset import Dataset_maker\n",
    "from ddad_utils.ddad import DDAD\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ba966",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('checkpoints/DDAD_TEST/train_losses.pickle', 'rb') as f:\n",
    "    loss = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss['train_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9dcd2",
   "metadata": {},
   "source": [
    "#### Îç∞Ïù¥ÌÑ∞ Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05918359",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"./ddad_utils/config.yaml\")\n",
    "\n",
    "device = torch.device(config.model.device)\n",
    "torch.manual_seed(config.model.seed)\n",
    "\n",
    "csv_path = \"Dataset/ECG_Test_with_anomaly.csv\"\n",
    "label_path = \"Dataset/ECG_Anomaly_PointLabels.npy\"\n",
    "\n",
    "# Define dataset and dataloader\n",
    "test_dataset = Dataset_maker(\n",
    "    root='./Dataset',\n",
    "    config=config,\n",
    "    is_train=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.data.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.model.num_workers,\n",
    ")\n",
    "\n",
    "point_labels = np.load(label_path).flatten()  # ÏãúÏ†êÎ≥Ñ Ïù¥ÏÉÅ ÎùºÎ≤®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c741e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2640721/48172872.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
      "  2%|‚ñè         | 40/1640 [08:05<5:23:22, 12.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m pred_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m ddad \u001b[38;5;241m=\u001b[39m DDAD(model, config)\n\u001b[0;32m---> 15\u001b[0m reconstructed_list, forward_list, gt_list, pred_scores, pred_mask \u001b[38;5;241m=\u001b[39m \u001b[43mddad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/ddad_utils/ddad.py:47\u001b[0m, in \u001b[0;36mDDAD.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# label: Ï†ïÏÉÅ=0, Ïù¥ÏÉÅ=1 (Ï†ïÏàòÌòï)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Ïù¥ÏÉÅ Ï†êÏàò Í≥ÑÏÇ∞ (MSE ÎòêÎäî MAE Í∞ÄÎä•)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m score \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(x0 \u001b[38;5;241m-\u001b[39m x), dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# (B,)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/ddad_utils/reconstruction.py:47\u001b[0m, in \u001b[0;36mReconstruction.__call__\u001b[0;34m(self, x, y, w)\u001b[0m\n\u001b[1;32m     43\u001b[0m t_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),), t, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     45\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y}\n\u001b[0;32m---> 47\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m x_t \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     54\u001b[0m all_xt\u001b[38;5;241m.\u001b[39mappend(x_t)\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/models/gaussian_diffusion.py:402\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, cond_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    378\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    385\u001b[0m ):\n\u001b[1;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Sample x_{t-1} from the model at the given timestep.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    :param model: the model to sample from.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m             - 'pred_xstart': a prediction of x_0.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     noise \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mrandn_like(x)\n\u001b[1;32m    411\u001b[0m     nonzero_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    412\u001b[0m         (t \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m([\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    413\u001b[0m     )  \u001b[38;5;66;03m# no noise when t == 0\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/models/respace.py:92\u001b[0m, in \u001b[0;36mSpacedDiffusion.p_mean_variance\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     91\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/models/gaussian_diffusion.py:279\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m B, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (B,)\n\u001b[0;32m--> 279\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    281\u001b[0m     model_output, extra \u001b[38;5;241m=\u001b[39m model_output\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/models/respace.py:129\u001b[0m, in \u001b[0;36m_WrappedModel.__call__\u001b[0;34m(self, x, ts, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m new_ts \u001b[38;5;241m=\u001b[39m map_tensor[ts]\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# if self.rescale_timesteps:\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m#     new_ts = new_ts.float() * (1000.0 / self.original_num_steps)\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/models/dit.py:232\u001b[0m, in \u001b[0;36mDiT.forward\u001b[0;34m(self, x, t, y)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, y):\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    Forward pass of DiT.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    x: (B, C, T)\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    t: (B,) tensor of diffusion timesteps\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m    y: (B,) tensor of class labels\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed  \u001b[38;5;66;03m# (B, num_patches, embed_dim)\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_embedder(t)                   \u001b[38;5;66;03m# (B, embed_dim)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_embedder(y)                  \u001b[38;5;66;03m# (B, embed_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Yonsei/ADGM/AnomalyDiT/models/dit.py:56\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DiT(\n",
    "    input_size=config.data.seq_len,\n",
    "    patch_size=5,\n",
    "    in_channels=config.data.input_channel,\n",
    "    num_classes=2\n",
    ").to(device)\n",
    "\n",
    "best_model_path = os.path.join(config.model.checkpoint_dir, config.model.exp_name, f\"{config.model.checkpoint_name}_best.pt\")\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "pred_scores = []\n",
    "\n",
    "ddad = DDAD(model, config)\n",
    "reconstructed_list, forward_list, gt_list, pred_scores, pred_mask = ddad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e108f3d",
   "metadata": {},
   "source": [
    "#### Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiT(input_size=750, patch_size=5, in_channels=1, num_classes=42).to(device)\n",
    "model.load_state_dict(torch.load(\"dit_ts_model.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536dffeb",
   "metadata": {},
   "source": [
    "#### ÏòàÏ∏°Í∞í ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f646560",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        x = x.to(device)\n",
    "        t = torch.zeros(x.size(0), dtype=torch.long).to(device)\n",
    "        out = model(x, t, y.to(device))  # (B, 2, 750)\n",
    "        mean_pred = out[:, 0, :]  # ÌèâÍ∑† Ï±ÑÎÑêÎßå ÏÇ¨Ïö©\n",
    "        pred_scores.append(mean_pred.cpu())\n",
    "\n",
    "pred_scores = torch.cat(pred_scores, dim=0).numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b57bd9",
   "metadata": {},
   "source": [
    "#### Precision-Recall Í∏∞Î∞ò threshold ÌÉêÏÉâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds_pr = precision_recall_curve(point_labels, pred_scores)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds_pr[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ccaff",
   "metadata": {},
   "source": [
    "#### ROC AUC Í≥ÑÏÇ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a812545",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds_roc = roc_curve(point_labels, pred_scores)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334671f",
   "metadata": {},
   "source": [
    "#### ÏµúÏ¢Ö Ïù¥ÏßÑ ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_binary = (pred_scores > best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27438b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚ñ∂ Best Threshold (by F1): {best_threshold:.4f}\")\n",
    "print(f\"‚ñ∂ Best F1 Score: {f1_scores[best_idx]:.4f}\")\n",
    "print(f\"‚ñ∂ Precision at best: {precision[best_idx]:.4f}\")\n",
    "print(f\"‚ñ∂ Recall at best: {recall[best_idx]:.4f}\")\n",
    "print(f\"‚ñ∂ ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a680ce",
   "metadata": {},
   "source": [
    "#### F1-score vs Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(thresholds_pr, f1_scores[1:], label=\"F1-score\")\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label=f\"Best Threshold = {best_threshold:.4f}\")\n",
    "plt.title(\"F1-score vs Threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aaeed1",
   "metadata": {},
   "source": [
    "#### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260db868",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(recall, precision, label='PR Curve')\n",
    "plt.scatter(recall[best_idx], precision[best_idx], color='red', label='Best F1 Point')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba8d1f",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e110243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef22ff",
   "metadata": {},
   "source": [
    "#### ÏÑ±Îä• Ï∂úÎ†•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîç F1-score Í∏∞Ï§Ä ÏµúÏ†Å threshold: {best_threshold:.4f}\")\n",
    "print(classification_report(point_labels, pred_binary, target_names=[\"Ï†ïÏÉÅ\", \"Ïù¥ÏÉÅ\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9606b",
   "metadata": {},
   "source": [
    "#### ÏòàÏ∏° Ï†êÏàò ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6673ba9",
   "metadata": {},
   "source": [
    "ÌååÎûÄÏÉâ ÏÑ†: Î™®Îç∏Ïù¥ Ï∂úÎ†•Ìïú Í∞Å ÏãúÏ†êÏùò ÏòàÏ∏° score (pred_scores)\n",
    "\n",
    "Ï£ºÌô©ÏÉâ ÏòÅÏó≠: Ïã§Ï†ú Ïù¥ÏÉÅÏù¥ Ï°¥Ïû¨ÌïòÎäî ÏãúÏ†ê (point_labels)\n",
    "\n",
    "Îπ®Í∞Ñ Ï†êÏÑ†: F1-score Í∏∞Ï§ÄÏúºÎ°ú ÏÑ†ÌÉùÎêú threshold (0.5436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32157346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(pred_scores, label=\"Predicted Scores\", linewidth=1)\n",
    "plt.plot(point_labels * 1.0, label=\"True Anomaly\", linestyle='--')  # ‚úî Ïä§ÏºÄÏùº Ï°∞Ï†à\n",
    "plt.axhline(best_threshold, color='red', linestyle=':', label=f\"Threshold = {best_threshold:.4f}\")\n",
    "plt.title(\"Predicted Scores vs True Anomaly Labels\")\n",
    "plt.xlabel(\"Time Point Index\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4470f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390bbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(pred_scores, bins=100, color='steelblue')\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label=f\"Threshold = {best_threshold:.4f}\")\n",
    "plt.title(\"Distribution of Predicted Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú\n",
    "X = test_dataset.X.numpy()         # shape: (N, 1, T)\n",
    "test_series = X[:, 0, :]           # shape: (N, T)\n",
    "\n",
    "# point_labelsÏôÄ pred_scores reshape\n",
    "point_labels = point_labels.reshape(test_series.shape)\n",
    "pred_scores = pred_scores.reshape(test_series.shape)\n",
    "\n",
    "test_labels = test_dataset.y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "signal = test_series[i]\n",
    "true_anom = point_labels[i]\n",
    "pred_score = pred_scores[i]\n",
    "pred_anom = (pred_score > best_threshold).astype(int)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(signal, label=\"Signal\")\n",
    "plt.plot(true_anom * np.max(signal), label=\"True Anomaly\", linestyle='--')\n",
    "plt.plot(pred_anom * np.max(signal), label=\"Predicted Anomaly\", linestyle=':')\n",
    "plt.title(f\"Sample {i} - True vs Predicted Anomalies\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≥†Ïú† ÌÅ¥ÎûòÏä§ Î™©Î°ù\n",
    "unique_classes = sorted(np.unique(test_labels))\n",
    "\n",
    "# subplot ÏãúÍ∞ÅÌôî\n",
    "n_rows, n_cols = 6, 7  # 42Í∞ú ÌÅ¥ÎûòÏä§ Í∏∞Ï§Ä\n",
    "plt.figure(figsize=(22, 18))\n",
    "\n",
    "for idx, cls in enumerate(unique_classes):\n",
    "    # Ìï¥Îãπ ÌÅ¥ÎûòÏä§Ïùò Ï≤´ Î≤àÏß∏ ÏãúÍ≥ÑÏó¥ index Ï∞æÍ∏∞\n",
    "    sample_idx = np.where(test_labels == cls)[0][0]\n",
    "    \n",
    "    signal = test_series[sample_idx]\n",
    "    true_anom = point_labels[sample_idx]\n",
    "    pred_score = pred_scores[sample_idx]\n",
    "    pred_anom = (pred_score > best_threshold).astype(int)\n",
    "\n",
    "    plt.subplot(n_rows, n_cols, idx + 1)\n",
    "    plt.plot(signal, label='Signal', linewidth=1)\n",
    "    plt.plot(true_anom * np.max(signal), '--', label='True Anomaly', linewidth=1)\n",
    "    plt.plot(pred_anom * np.max(signal), ':', label='Predicted Anomaly', linewidth=1)\n",
    "    plt.title(f\"Class {cls+1} (idx {sample_idx})\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(True)\n",
    "\n",
    "# Ï†ÑÏ≤¥ Ï†úÎ™© Î∞è Î≤îÎ°Ä\n",
    "plt.suptitle(\"Class-wise Anomaly Detection: True vs Predicted\", fontsize=18, y=0.92)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.15, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db07ab",
   "metadata": {},
   "source": [
    "## Ïù¥Ï†Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbe4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/Pro/Desktop/AnomalyDiT-main/AnomalyDiT-main/Dataset/ECG_Train_with_anomaly.csv', sep='\\t', index_col=False, header=None)\n",
    "test = pd.read_csv('C:/Users/Pro/Desktop/AnomalyDiT-main/AnomalyDiT-main/Dataset/ECG_Test_with_anomaly.csv', sep='\\t', index_col=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f71be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.Tensor(train.drop(columns=0).to_numpy()).unsqueeze(1)\n",
    "test = torch.Tensor(test.drop(columns=0).to_numpy()).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DiT(input_size=750,\n",
    "        patch_size=5,\n",
    "        in_channels=1,\n",
    "        hidden_size=300,\n",
    "        depth=28,\n",
    "        num_heads=10,\n",
    "        mlp_ratio=4.0,\n",
    "        class_dropout_prob=0.1,\n",
    "        learn_sigma=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373848c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,1,750)\n",
    "y = test[:4]\n",
    "t = torch.randint(low=0, high=10000, size=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013498da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
